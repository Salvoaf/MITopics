-  What we believe is right risks becoming no longer  question of ethics but simply what the correct result of  mathematical calculation is 


-  ,  Unfortunately ,   closer look at how we are using AI systems today suggests that we may be wrong in assuming that their growing power is mostly for the good 


-  While much of the current critique of AI is still framed by science fiction dystopias ,  the way it is being used now is increasingly dangerous 


-  This risks changing our morality in fundamental ,  perhaps irreversible ,  ways ,  as we argued in our recent essay in Academy of Management Learning  Education  ( which weve drawn on for this article )  


-  Judgment relies not only on reasoning but also ,  and importantly so ,  on capacities such as imagination ,  reflection ,  examination ,  valuation ,  and empathy 


-  The problem is that having processed our data ,  the answers these systems give are constrained by the narrow objectives for which they were designed ,  without regard for potentially harmful consequences that violate our moral standards of justice and fairness 


-  Algorithms are nothing more than precise recipes that specify the exact sequence of steps required to solve  problem ,  as one definition puts it 


-  ,  But as the examples above suggest ,  this gap between our inflated expectation of what an algorithm can do and its actual capabilities can be dangerous 


-   technical image is the computed transformation of digitalized data about some object or idea ,  and ,  as such ,  it is  representation of the world 


-  The trouble with AI systems is that we cannot fully understand how the machine draws its technical images  what it emphasizes ,  what it omits ,  and how it connects pieces of information in transitions toward the technical image 


-  ,  Consider ,  for instance ,  the way people use wearable electronic devices that monitor bodily functions ,  including pulse rate ,  steps taken ,  temperature ,  and hours of sleep ,  as indicators of health 


-  Instead of asking yourself how you feel ,  you can check your wearable 


-  It may tell you that you should be concerned because you dont take the minimum number of steps generally recommended for  healthy life   target that may make sense for many but could be counterproductive if the air quality is bad or you have weak lungs 


-  Our trust in AI leads us to confuse reckoning  decision-making based on the summing up of various kinds of data and technical images  with judgment 


-  We see (  )  in AIs confident answers the kind of certainty that our ancestors sought in vain in entrails ,  tarot cards ,  or the stars above 


-  ,  Some observers  scholars ,  managers ,  policy makers  believe that following responsible AI development principles is  valid and effective approach to injecting ethical considerations into AI systems 


-  We agree when they argue that as  cultural product ,  AI is bound to reflect the outlooks of people who commissioned the algorithm ,  wrote its code ,  and then used the program 


-  We disagree when they say that therefore careful attention to the overall project and its programming is all that is needed to keep the results mostly positive 


-  Critical voices about our ability to instill ethics into AI are increasing ,  asking the basic question of whether we can teach ethics to AI systems in the first place 


-  Going back to the roots of AI ,  we should realize that the very fundaments of judgment and reckoning are different and cannot be reconciled 


-  ,  Those who believe in ethical AI consider the technology to be  tool ,  on par with other tools that are essentially extensions of the human body ,  such as lenses  ( to extend the view of the eyes )  ,  or spoons and screwdrivers  ( to extend the dexterity of the hands )  


-  In our view ,  as with wearables ,  its crucial to consider the user as part of the tool: We need to think hard about how algorithms shape us 


-  If the substitution of data-driven reckoning for human judgment is something to be very cautious about ,  then following the rallying cry to develop responsible AI will not help us break the substitution 


-  What can we do? ,  We see two ways forward 


-  ,  First ,  we want to make  call for inaction: We need to stop trying to automate everything that can be automated just because it is technically feasible 


-  Mesmerized by the promise of eternal improvement ,  technological solutionism blunts our ability to think deeply about whether ,  when ,  how ,  and why to use  given tool 


-  As  society ,  we need to learn what AI really is and how to work with it 


-  Specifically ,  we need to learn how to understand and use its technical images ,  just as we needed to learn how to work with models and maps  not just in  general ,  abstract ,  and idealized sense ,  but for each specific project where it is envisioned 


-  For example ,  while algorithms gain greater predictive power when fed more data ,  they will always assume  static model of society ,  when ,  in fact ,  time and context are ever changing 


-  And once managers have judged AI to be  useful tool for  given project ,  we see essential merit in managers developing and maintaining an attitude of vigilance and doubt 


-  This is because ,  in the absence of vigilance and doubt ,  we might miss the moment when our decision-making frame has transitioned from judgment to reckoning 


